---
title: "Tests statistiques simples avec R"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    df_print: paged
runtime: shiny_prerendered
description: >
  Tests statistiques avec R.
---


```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(janitor)
library(DT)
library(car)
tutorial_options(exercise.timelimit = 10)

BeanSurvey<-read.csv("bean_survey.csv")[,-1]

BeanSurvey$AGEHH<-c(32,57,20,55,78,42,28,49,41,54,65,63,32,29,43,68,53,39,25,44,23,47,32,26,25,29,44,23,58,69,26,65,75,51,38,24,35,29,37,45,50,23,60,32,70,43,51,28,65,33)


BeanSurvey<-mutate(BeanSurvey,GENDERHH=ifelse(is.na(GENDERHH),"male",as.character(GENDERHH)))

```


## Vue d'ensemble

Effectuer des tests statistiques simples avec R est assez facile. Dans ce tutoriel, nous allons voir comment réaliser certains tests très couramment utilisés - le test t et le test du chi-deux, ainsi que les équivalents non paramétriques que vous pouvez utiliser dans les cas où les hypothèses ne sont pas satisfaites. Nous partons du principe que vous avez probablement déjà rencontré ces méthodes, mais vous pouvez également consulter certaines des ressources liées pour vous rafraîchir la mémoire.

En général, ces tests simples peuvent être un point de départ utile, mais sont limités dans ce qu'ils peuvent vous dire. C'est pourquoi, dans le prochain module du cours, nous parlerons davantage de la modélisation statistique, qui vous permet d'étendre les principes de ces tests statistiques et de les développer pour qu'ils soient applicables dans davantage de situations et puissent être appliqués de manière beaucoup plus intéressante que ces simples tests.

Nous allons utiliser le même jeu de données `BeanSurvey` que nous avons examiné plus tôt dans le cours pour faire des graphiques et des manipulations de données et nous allons maintenant étendre cela à certains tests statistiques. Les données sont intégrées à la fin de ce classeur si vous voulez un rappel sur ce que ces données contiennent, et comment les variables sont nommées.


Il existe de nombreuses ressources expliquant les mécanismes de base du test t dans R. Vous trouverez un guide intéressant [ici] (https://uc-r.github.io/t_test#twosample).

Comme vous le verrez, les fonctions elles-mêmes sont assez simples. Et, vous serez peut-être heureux d'apprendre qu'il n'y a pas beaucoup de nouvelles fonctions à apprendre dans ce module, surtout par rapport aux modules précédents !

Cependant, il est extrêmement important d'utiliser ces fonctions dans le bon contexte et de savoir quoi faire lorsque les résultats sont inattendus. L'une des gros avantages avec R est la possibilité d'avoir une methode de travail reproductible en utilisant des fichiers R markdown pour stocker les commandes et les explications. Dans les vidéos de ce module, nous parlons d'un tel exemple, en essayant de mettre l'accent sur la réflexion de ce qui est fait, sur l'interpretation et sur la façon dont on pourrait améliorer le travail. 
Nous en apprendrons davantage sur l'extension de cette approche des tests d'hypothèse à des modèles statistiques plus complets dans le prochain module de ce cours.

![](https://youtu.be/LVcmN2OSXY8)

La deuxième partie de la vidéo sera présentée plus tard dans le tutoriel.

## Le test t

Nous pouvons utiliser un test t (ou test de student) lorsque nous voulons comparer les moyennes d'une variable numérique entre deux groupes, afin de déterminer si la différence est statistiquement significative.

Ainsi, si nous repensons à notre ensemble de données `BeanSurvey` - nous pourrions chercher à savoir si la superficie moyenne des terrains possédée par les ménages dirigés par des hommes est différente de la superficie moyenne de terrains détenue par les ménages dirigés par des femmes. Nous devrions toujours commencer par explorer nos données ! 

### Analyse préliminaire

Avant tout test statistique formel, essayez de toujours d'abord explorez les résumés statistiques et les graphiques montrant la relation qui vous intéresse.

Et c'est l'occasion parfaite d'appliquer et de récapituler toutes vos connaissances sur ggplot2 recemment acquises ! 

*Essayez de reproduire les trois sorties suivantes sortie pour montrer 1) les moyennes et les écarts types de `LANDAREA` par `GENDERHH` ainsi que le nombre d'observations dans chaque groupe; 2) l'histogramme de `LANDAREA` pour chaque groupe definie par `GENDERHH`; 3) un graphique en boite a moustache (boxplot) de `LANDAREA` par `GENDERHH`*.

**1) les moyennes et les écarts types de `LANDAREA` par `GENDERHH` ainsi que le nombre d'observations dans chaque groupe**
```{r,echo=FALSE,message=FALSE}
BeanSurvey %>% 
   group_by(GENDERHH) %>%
    summarise(n=n(),mean=mean(LANDAREA,na.rm=T),sd=sd(LANDAREA,na.rm=T))
```

```{r summarystats, exercise=TRUE,error=TRUE}

```


```{r summarystats-solution}
BeanSurvey %>% 
   group_by(GENDERHH) %>%
    summarise(n=n(),mean=mean(LANDAREA,na.rm=T),sd=sd(LANDAREA,na.rm=T))
```


**2) l'histogramme de `LANDAREA` pour chaque groupe definie par `GENDERHH`**
```{r,echo=FALSE,message=FALSE}
BeanSurvey %>% 
  ggplot(aes(x=LANDAREA))+
    geom_histogram()+
      facet_wrap(~GENDERHH)

```

```{r summaryplot, exercise=TRUE}

```

```{r summaryplot-solution}
BeanSurvey %>% 
  mutate(YIELD_LR =BEANSHARVESTED_LR/LANDAREA ) %>%
  ggplot(aes(x=YIELD_LR))+
    geom_histogram()+
      facet_wrap(~VILLAGE)

```


**3) un graphique en boite a moustache (boxplot) de `LANDAREA` par `GENDERHH`**
```{r,echo=FALSE,message=FALSE}

BeanSurvey %>% 
  ggplot(aes(y=LANDAREA,x=GENDERHH))+
    geom_boxplot()
```

```{r summaryplot2, exercise=TRUE}

```

```{r summaryplot2-solution}

BeanSurvey %>% 
  ggplot(aes(y=LANDAREA,x=GENDERHH))+
    geom_boxplot()
```

En regardant les resumes statistiques, nous pouvons voir que les valeurs moyennes sont un peu plus élevées pour les ménages dirigés par des hommes que pour ceux dirigés par des femmes.

Les boxplots et les histogrammes montrent que la distribution de la superficie est généralement un peu plus élevée pour les ménages dirigés par un homme, ce qui se traduit par un déplacement plus important de la médiane et des quartiles dans les cases. Cependant, nous constatons également que la distribution est faussée par certaines grandes valeurs - la plupart des agriculteurs ont moins de 3 acres de terre, mais un petit nombre d'entre eux ont des rendements beaucoup plus élevés. 

Les graphiques et les statistiques récapitulatives suggèrent que l'hypothèse selon laquelle les ménages dirigés par un homme ont, en moyenne, plus de terres que les ménages dirigés par une femme, semble raisonnable. Nous pouvons effectuer un test de signification statistique formel pour voir s'il y a suffisamment de preuves pour confirmer cette hypothèse, ou si les différences observées dans les données ne sont pas plus importantes que ce que nous nous attendrions à voir par hasard.

### Exécution du test t

Nous pouvons utiliser un test t lorsque nous avons une variable numérique continue et que nous voulons soit comparer si la valeur moyenne est significativement différente d'une valeur de référence fixe (un test t à un échantillon), soit si la valeur moyenne est significativement différente entre deux groupes (un test t à deux échantillons). Dans ce cas, nous avons des données appropriées à utiliser - une variable numérique `LANDAREA` et une variable catégorielle à deux niveaux `GENDERHH`.

La structure de la fonction `t.test` est que nous fournissons le nom de notre variable numérique (`LANDAREA`), suivi d'un tilde (`~`), suivi du nom de notre variable de regroupement à 2 niveaux (`GENDERHH`). Ensuite, nous avons besoin du nom de nos données. 

```{r ttest1, exercise=TRUE}
t.test(LANDAREA~GENDERHH,data=BeanSurvey)
```

Dans ce cas, nous conclurions, à partir de la valeur p de 0,2496 qu'il n'y a pas de preuve permettant de conclure qu'il existe une différence significative dans les valeurs moyennes de la superficie des terres en fonction du sexe du chef de ménage.

Le résultat nous montre également la statistique t, les degrés de liberté et un intervalle de confiance de 95 % autour de la différence des moyennes.

Il est utile de se rappeler comment fonctionnent les valeurs p, car elles sont très souvent mal comprises et donc mal interprétées. Il existe une excellente vidéo du Dr Nic sur les valeurs p [Ici](https://www.youtube.com/watch?v=eyknGvncKLw)


Avec la fonction `t.test`, il est important de noter que, contrairement à la plupart des fonctions que nous avons utilisées jusqu'à présent dans ce cours, le nom des données vient comme deuxième argument *après* la formule. 

Nous pouvons utiliser un pipe (`%>%`) pour passer des données au test t, mais nous devons l'utiliser d'une manière légèrement différente. Le pipe suppose que le premier argument d'une fonction est la donnée, mais nous pouvons passer outre. Dans `t.test`, ou dans n'importe quelle fonction où les données ne sont pas le premier argument, après le pipe, nous pouvons inclure un argument `data= .`. Le `.` indique que l'on hérite des données provenant de la ligne précédente.


```{r pipein, exercise=TRUE}
BeanSurvey %>% 
     t.test(YIELD_LR~VILLAGE,data=.)

```
Et c'est tout ! Nous vous avons montré comment faire un test t dans R...

... mais ! Il y a également d'autres éléments plus pratiques à prendre en compte lors de l'exécution d'un test t : il faut se demander si l'hypothèse et les hypothèses qui la sous-tendent sont raisonnables. Et nous devons savoir quoi faire si nous rencontrons quelque chose qui nous fait douter de la validité des méthodes.

Il existe en fait une hypothèse que l'on vous a probablement enseignée lors de l'apprentissage du test t et dont vous n'avez pas à vous soucier du tout lorsque vous utilisez la fonction `t.test` dans R.

### Hypothèse 0 : Egalité des variances 

Le résultat que vous obtenez par défaut à partir de la fonction `t.test` n'est pas exactement le même que celui que vous verriez dans d'autres logiciels, car R a des paramètres par défaut légèrement différents.

Vous avez probablement appris que vous devez avoir approximativement une "variance égale" dans vos deux groupes pour qu'un test t soit valide. Cependant, par défaut, R utilise un test t de "Welch". Il s'agit d'une modification du test t classique qui ne nécessite pas une variance égale. 

Il n'y a aucune raison réelle de ne pas utiliser cette modification. Si les variances sont exactement égales, les tests t classique et de Welch fourniront des résultats identiques ; et lorsque les variances sont très similaires, les différences entre les résultats sont insignifiantes.

Mais si les variances ne sont pas similaires, les résultats du test t classique ne seront pas valides alors que ceux du test t de Welch le seront. En examinant les statistiques récapitulatives et les graphiques que nous avons produits précédemment, il semble que les variances ne soient pas égales - l'écart type est beaucoup plus important pour les ménages dirigés par des hommes que pour ceux dirigés par des femmes. Ainsi, dans ce cas, nous voudrions presque certainement conserver la valeur par défaut de R et utiliser la version de Welch du test t.

Mais, si vous aimez vraiment le test t classique, ou si vous voulez simplement être sûr que les résultats correspondent à ceux que vous avez pu voir en exécutant le même code dans un autre logiciel, alors vous pouvez ajouter l'argument `var.equal = TRUE` dans le code

```{r ttest, exercise=TRUE}
t.test(LANDAREA~GENDERHH,data=BeanSurvey,var.equal=TRUE)

```

Comme vous pouvez le voir, si vous revenez en arrière et comparez les résultats à la sortie précédente, la valeur de la statistique t et les degrés de liberté changent très légèrement, tout comme la valeur p. Dans ce cas, cela n'aurait pas fait de différence substantielle dans nos conclusions, malgré le changement assez important de la valeur p. Dans ce cas, cependant, cela n'aurait pas fait de différence substantielle dans nos conclusions, malgré le changement assez important de la p-value. Dans d'autres cas, cela pourrait faire la différence entre un résultat significatif et un résultat non significatif, et nous devrions donc bien réfléchir avant de supposer que l'hypothèse de variance égale est valide.

### Hypothèse 1 : Normalité

Nous avons également une autre hypothèse selon laquelle nous avons une normalité approximative de la réponse pour chaque groupe. Le mot clé ici est "approximatif" ; beaucoup de gens peuvent se demander s'ils ont une distribution parfaitement normale. En fait, à mesure que nous augmentons la taille de nos données, le test t reste valide avec des distributions d'apparence de moins en moins normales. C'est ce qu'on appelle le "théorème de la limite centrale".

Une fois de plus, le Dr Nic est de garde avec une vidéo à ce sujet. [ici](https://www.youtube.com/watch?v=_YOr_yYPytM&ab_channel=DrNic%27sMathsandStats)

Il est généralement utile de vérifier l'histogramme pour s'assurer que nous avons une distribution à peu près symétrique, c'est-à-dire unimodale. 

Il existe des tests d'hypothèse formels que l'on peut utiliser pour 'tester' la normalité et que certaines personnes peuvent vous apprendre. Mais ils sont totalement inutiles dans ce contexte.

Il n'existe aucune hypothèse exigeant une normalité 'exacte'. Et en utilisant les tests de normalité, plus nous disposons de données, plus nous avons de chances d'identifier que quelque chose n'est pas 'exactement' normal. C'est exactement le contraire de ce dont nous avons besoin pour satisfaire cette hypothèse du test t, en raison du théorème de la limite centrale !

Ainsi, une simple inspection visuelle des distributions à partir d'un histogramme est généralement suffisante pour nous permettre de déterminer si nos données répondent à cette hypothèse.

Dans ce cas particulier, nous n'avons probablement pas assez de données pour pouvoir invoquer le théorème de la limite centrale. Et les histogrammes que nous avons produits précédemment suggéraient une distorsion très importante des données. Nous devons donc envisager des alternatives possibles. 

### Alternative non paramétrique : Test de Wilcoxon

Une solution courante à ce problème serait d'utiliser un test non paramétrique, comme le test de la somme des rangs de Wilcoxon, également connu sous le nom de test U de Mann-Whitney.

Au lieu de vérifier si les valeurs moyennes diffèrent entre les groupes, ce test examine si la distribution des revenus est modifiée pour les hommes par rapport aux femmes, plutôt que de vérifier si la valeur moyenne est différente. 

Cela fonctionne en classant les valeurs dans chaque groupe et en comparant les rangs moyens dans les deux groupes. Cela permet de résister à toutes sortes de distributions étranges, car la valeur maximale ne peut jamais être supérieure de plus d'une unité à la valeur supérieure suivante. 

Cependant, il a moins de puissance statistique pour détecter les différences entre les groupes qu'un test t, c'est pourquoi le test t est souvent préféré.

Heureusement, dans R, le code de la fonction `wilcox.test` est presque identique à celui que nous avons déjà vu avec `t.test`. Ainsi, passer à un test non-paramétrique est simple ! Nous changeons simplement `t.` par `wilcox.`.

```{r wilcox1,exercise=TRUE}
  wilcox.test(LANDAREA~GENDERHH,data=BeanSurvey)
```

Et ici, nous obtenons un résultat similaire avec une valeur p de p=0,3469 suggérant que nous n'avons aucune preuve contre l'hypothèse nulle selon laquelle la distribution de la superficie des terres pour les hommes est la même que celle des revenus pour les femmes. Cela renforce donc notre conclusion initiale du t-test.  

Notez que l'hypothèse est décrite dans le résultat comme un "changement de localisation" - c'est une autre façon de considérer la "moyenne des rangs". Une autre façon de formuler l'hypothèse pour ce test spécifique serait que notre résultat significatif suggère que les hommes sont plus susceptibles d'avoir des revenus supérieurs au revenu médian. 

En raison de l'existence de liens, le test de Wilcoxon ne permet pas de comparer directement les valeurs médianes. Dans la vidéo, vous aurez vu un exemple où les médianes des deux groupes sont les mêmes mais où le test de Wilcoxon fournit un résultat significatif.

Vous pouvez vous faire une meilleure idée du fonctionnement du test de Wilcoxon en utilisant la fonction `rank()` pour classer les valeurs, puis calculer la moyenne des rangs et la pipe dans un graphique ou un résumé statistique.

La fonction `rank()` est assez simple, si nous fournissons un vecteur de nombres, elle donnera le rang 1 au plus petit, 2 au plus petit suivant et ainsi de suite.


```{r ranksimple,exercise=TRUE}

some_numbers<-c(45,1,100,8)

some_numbers
rank(some_numbers)

```

Nous pouvons donc ajouter les rangs de `LANDAREA` dans une nouvelle colonne de nos données en utilisant `mutate` et ensuite étudier les statistiques récapitulatives sur cette nouvelle variable de rang pour mieux comprendre la comparaison effectuée dans le test de Wilcoxon.


```{r rank2,exercise=TRUE}
BeanSurvey %>%
  select(LANDAREA,GENDERHH) %>%
  mutate(land_rank=rank(LANDAREA))
```

```{r rank5,exercise=TRUE}
BeanSurvey %>%
  select(LANDAREA,GENDERHH) %>%
  mutate(land_rank=rank(LANDAREA)) %>%
    ggplot(aes(y=land_rank,x=GENDERHH))+
      geom_boxplot()
```


```{r rank3,exercise=TRUE}
BeanSurvey %>%
  select(LANDAREA,GENDERHH) %>%
  mutate(land_rank=rank(LANDAREA)) %>%
    group_by(GENDERHH) %>%
      summarise(mean(land_rank))
```

La plus petite valeur est classée 1, la deuxième plus petite valeur est classée 2 et ainsi de suite. Lorsque nous comparons la distribution des rangs, nous pouvons constater que les rangs sont un peu plus élevés (c'est-à-dire que la surface est plus grande) pour les ménages dirigés par un homme, mais la différence n'est pas assez importante pour conclure que cette différence est plus grande que ce que nous pourrions voir par hasard.

Si vous ne l'avez pas encore rencontré, vous pouvez en savoir plus sur le test de la somme des rangs de Wilcoxon [ici](https://www.stat.auckland.ac.nz/~wild/ChanceEnc/Ch10.wilcoxon.pdf). 

### Hypothèse 2 : Indépendance

Probablement, l'hypothèse la plus importante à considérer est de savoir si les observations sont indépendantes les unes des autres dans les deux groupes. L'exemple le plus simple où ce n'est pas le cas est celui des données appariées. Dans ce scénario, nous utiliserions un test t apparié, et cela peut également être réalisé en utilisant `t.test()`. Cependant, nous appliquons cette fonction d'une manière assez différente lorsque nous effectuons le test t apparié, par rapport à l'exemple précédent que nous avons vu, lorsque nous avons appliqué un test t indépendant à deux échantillons.


Un bon exemple de ceci serait de comparer des haricots plantés pendant des pluies courtes à des haricots plantés pendant des pluies longues. Nous pouvons produire des histogrammes ou des boxplots séparés pour les haricots plantés pendant les longues pluies et les haricots plantés pendant les courtes pluies, en utilisant des appels séparés à `ggplot()`. Parce qu'ils sont dans des variables différentes, nous ne pouvons pas directement les faire correspondre sur le même graphique comme nous l'avons vu auparavant - nous devrions d'abord faire une manipulation supplémentaire des données. Nous en apprendrons davantage à ce sujet dans le dernier module du cours, qui rendra les choses un peu plus claires, mais la production de deux graphiques distincts reste un moyen efficace d'explorer les données ici.  

```{r pair1,exercise=TRUE ,echo=FALSE}
ggplot(data=BeanSurvey)+
  geom_boxplot(aes(y=BEANSPLANTED_LR,x=1))+
  geom_boxplot(aes(y=BEANSPLANTED_SR,x=2))+
  scale_x_continuous(breaks=1:2,labels=c("LR","SR"))
```
. Nous avons également dû utiliser un code différent de celui que nous avons vu précédemment. En effet, nous avons plusieurs variables pour les groupes, plutôt qu'une variable pour le résultat et une variable pour le facteur de regroupement. Pour réaliser ce graphique, j'ai donc défini l'esthétique dans les fonctions `geom_()` plutôt que dans la fonction `ggplot()`. Nous pouvons faire cela si nous voulons utiliser différentes variables pour différentes géométries. Dans mes deux appels à la fonction `geom_boxplot()`, je fixe une valeur constante pour l'axe des x et je m'assure ensuite de l'étiqueter avec la balise.   

Bien que nos boxplots ressemblent à ce que nous avons vu auparavant en comparant les ménages dirigés par des hommes à ceux dirigés par des femmes, il y a une différence clé ici - les mêmes agriculteurs ont des observations à la fois pendant les longues pluies et les courtes pluies.

Ainsi, bien que nous puissions calculer les valeurs de moyenne et d'écart-type comme auparavant, nous n'avons pas besoin d'utiliser `group_by` puisque les variables sont différentes pour chaque groupe. 

```{r summ_groups, exercise=TRUE}
BeanSurvey %>%
  summarise(mean(BEANSPLANTED_LR,na.rm=T),sd(BEANSPLANTED_LR,na.rm=T),
            mean(BEANSPLANTED_SR,na.rm=T),sd(BEANSPLANTED_SR,na.rm=T))
```

Avec le test t apparié, nous utilisons également la même fonction `t.test`, mais avec une manière légèrement différente de spécifier les entrées.

Notez que cette fois, il n'est pas possible de faire un pipe dans le test t par paires car aucun des arguments n'est `data`, à la place nous devons fournir deux noms de variables individuelles. /*Beaucoup de fonctions fonctionnent avec des pipes, mais pas toutes !*/


```{r paired, exercise=TRUE}
t.test(BeanSurvey$BEANSPLANTED_LR,BeanSurvey$BEANSPLANTED_SR,paired=TRUE)
```
Dans ce cas, nous constatons que, même si nous plantons en moyenne plus de haricots pendant les longues pluies, soit 1,3 kg, nous n'avons pas suffisamment de preuves au niveau de signification de 5% pour conclure que cette différence est statistiquement significative (p=0,0978).

Une fois encore, nous pouvons être préoccupés par l'hypothèse de normalité. Avec le test t apparié, ce qui nous intéresse n'est pas la distribution des variables individuelles mais la distribution des différences au sein de chaque agriculteur. Nous pouvons donc utiliser `mutate` pour calculer la colonne des différences et ensuite regarder un histogramme.

```{r pairhist, exercise=TRUE}
BeanSurvey %>%
  mutate(PLANTED_DIFF=BEANSPLANTED_LR-BEANSPLANTED_SR) %>%
    ggplot(aes(x=PLANTED_DIFF))+
      geom_histogram()
```

Nous pouvons craindre que les résultats soient faussés par les deux valeurs très élevées, alors nous pourrions peut-être essayer à nouveau le test de Wilcoxan. Heureusement, cela fonctionne exactement comme avant. Le code `paired` de `wilcox.test` est le même que le code `paired` de `t.test`, il suffit de changer la fonction.

Nous pourrions craindre que les résultats soient faussés par les deux valeurs très élevées /*et, une fois encore, nous ne disposons pas d'un jeu de données très important et nous ne pouvons donc pas nous fier au théorème de la limite centrale*/. Nous pourrions donc essayer à nouveau le test de Wilcoxon. Et, heureusement, cela fonctionne exactement comme avant en suivant un modèle très similaire. Le code `paired` de `wilcox.test` est le même que le code `paired` de `t.test`, il suffit de changer la fonction.

```{r pairwilcox, exercise=TRUE}
wilcox.test(BeanSurvey$BEANSPLANTED_LR,BeanSurvey$BEANSPLANTED_SR,paired=TRUE)
```
Encore une fois, nous obtenons une conclusion similaire : nous n'avons pas suffisamment de preuves pour être sûrs que la différence entre les saisons dans les données est due à autre chose qu'au hasard.

Le test t apparié fonctionne dans ce scénario spécifique, mais il existe des violations plus complexes de l'indépendance, qui ne peuvent pas être corrigées aussi facilement. 

C'est notamment le cas lorsque nous envisageons d'avoir plus de deux observations appariées (par exemple, des données prises sur plusieurs points dans le temps), des plans expérimentaux avec blocage ou un échantillonnage en grappes dans les enquêtes. 

Dans ce cas, le test t n'est pas du tout une méthode d'analyse suffisante ! Vous devrez donc commencer à en apprendre davantage sur la modélisation statistique pour bien analyser vos données - et faire correspondre la structure de modèle appropriée à la structure de vos données.



## Test du khi-deux

![](https://youtu.be/a-hVoVnkWSg)

Un autre test statistique simple et courant est le test du chi-deux. Nous l'utilisons lorsque nous voulons comparer s'il y a ou non une relation entre deux variables catégorielles.

Dans ce cahier d'exercices, je vais vous montrer comment utiliser la bibliothèque `janitor` pour ce type d'analyse. Cela vous permet de produire des tableaux, des pourcentages, et des tests de chi-deux dans le même style tidyverse que `dplyr`.

Comme il s'agit d'un paquetage assez récent, lorsque vous regardez en ligne, il n'y a pas beaucoup de ressources qui adoptent cette approche particulière, et vous verrez plutôt d'autres fonctions, comme `table` ou `prop.table` être utilisées. Il y a toujours plus d'une façon de faire quelque chose en R. Pour moi, l'approche `janitor` est en fait beaucoup plus simple à suivre que l'approche traditionnelle.

Ainsi, à titre d'exemple, nous pouvons être intéressés par la relation entre le fait qu'un ménage vende des haricots, `SELLBEANS`, et le village `VILLAGE`.

### Analyse préliminaire

L'analyse préliminaire à laquelle nous nous intéresserions d'abord ici serait un tableau croisé comparant ces variables.  Nous pouvons pipeer `%>%` directement à partir des données dans la fonction `tabyl`, et ensuite spécifier les variables à inclure dans notre tableau croisé.

```{r tabyl1,exercise=TRUE}

BeanSurvey %>%
  tabyl(VILLAGE,SELLBEANS) 

```

La première variable sera toujours placée dans les lignes du tableau, et la deuxième variable sera placée dans les colonnes.

Essayez d'interpréter ces chiffres à partir de la sortie du tableau de fréquence, et voyez si vous pensez qu'il y a un modèle. C'est difficile ! Avec les tableaux croisés, il peut être assez difficile de déterminer s'il existe un modèle à partir des chiffres eux-mêmes. 

C'est pourquoi nous examinons souvent aussi les pourcentages marginaux. Il s'agit de déterminer, pour chaque niveau d'une variable, le pourcentage de répondants qui se situent dans les niveaux de la deuxième variable. 

Nous les appelons "pourcentages de ligne" ou "pourcentages de colonne", selon que nous examinons les pourcentages dans chaque ligne ou les pourcentages dans chaque colonne. Nous pouvons pipe le tableau de fréquence dans la fonction `adorn_percentages` pour étudier cela.

Par exemple, nous avons deux questions possibles :  "Quel est le pourcentage de personnes à Kimbugu qui vendent des haricots ?" C'est le "pourcentage de ligne" parce que nous cherchons dans les niveaux d'éducation, et l'éducation est le facteur de ligne. Le pourcentage de ligne est l'option par défaut, nous n'avons donc pas besoin d'ajouter autre chose à cette fonction.

```{r tabyl2,exercise=TRUE}

BeanSurvey %>%
  tabyl(VILLAGE,SELLBEANS) %>%
    adorn_percentages()
```
Par défaut, cela nous montre des proportions plutôt que des pourcentages joliment formatés. Mais nous pouvons faire un pipe dans une fonction supplémentaire, `adorn_pct_formatting` pour appliquer le formatage en pourcentage.

```{r tabyl3,exercise=TRUE}
BeanSurvey %>%
  tabyl(VILLAGE,SELLBEANS) %>%
    adorn_percentages() %>%
      adorn_pct_formatting()
```

Nous pouvons donc voir que 54% des habitants de Kimbugu vendent des haricots, et que seulement 15% des habitants de Lwala en vendent.

Ou nous pourrions demander "Quel est le pourcentage de personnes qui vendent des haricots et qui vivent à Kimbugu". Nous devons ajouter l'argument "col" dans la fonction `adorn_percentages` pour l'obtenir.

```{r tabyl4,exercise=TRUE}
BeanSurvey %>%
  tabyl(VILLAGE,SELLBEANS) %>%
    adorn_percentages("col") %>%
      adorn_pct_formatting()
```

Nous pouvons donc voir ici que 77% de ceux qui vendent des haricots vivent à Kimbugu.

Il ne s'agit pas d'une contradiction ! 

Il faut toujours bien réfléchir aux pourcentages que l'on calcule, et se demander lequel serait le plus logique à interpréter. 

Dans ce cas, les pourcentages en ligne nous seraient probablement beaucoup plus utiles que les pourcentages en colonne. La question la plus intéressante, et probablement la plus facile à interpréter, serait de comparer les niveaux relatifs de vente de haricots dans les différents villages.

Pour représenter ces résultats sous forme de graphique, nous voudrions probablement produire des diagrammes à barres. Il existe plusieurs façons de réaliser des diagrammes en bâtons, comme nous l'avons appris plus tôt dans le cours - en les empilant ou en utilisant des facettes. 

*Voyez si vous pouvez reproduire le graphique ci-dessous, ou si vous pouvez choisir de produire un graphique différent qui montre la relation entre `VILLAGE` et `SELLBEANS`. N'oubliez pas de modifier l'échelle sur l'axe des x pour le rendre plus lisible !*
```{r ggbar0,echo=FALSE}
ggplot(data=BeanSurvey,aes(group=SELLBEANS,fill=SELLBEANS,y=VILLAGE))+
  geom_bar(position="fill")+
   scale_x_continuous(breaks=c(0,0.2,0.4,0.6,0.8,1),labels=c("0%","20%","40%","60%","80%","100%"))
```

```{r ggbar1,exercise=TRUE}

```

```{r ggbar1-solution}
ggplot(data=BeanSurvey,aes(group=SELLBEANS,fill=SELLBEANS,y=VILLAGE))+
  geom_bar(position="fill")+
   scale_x_continuous(breaks=c(0,0.2,0.4,0.6,0.8,1),labels=c("0%","20%","40%","60%","80%","100%"))
```

### Exécution du test

Pour exécuter le test du chi carré, nous devons avoir le tableau de fréquence à deux voies exactement tel qu'il résulte de l'exécution de la ligne de code `tabyl()`. Ceci est ensuite pipé directement dans la fonction `chisq.test`.

```{r chi1,exercise=TRUE}
BeanSurvey %>%
  tabyl(VILLAGE,SELLBEANS) %>%
    chisq.test()
```

Et nous obtenons une valeur p de 0.0095, ce qui signifie qu'ici nous avons suffisamment de preuves pour conclure que les fermiers de Kimbugu sont plus susceptibles de vendre leurs haricots par rapport aux fermiers de Lwala.


Assurez-vous que vous pipez depuis le tableau de fréquence, créé par `tabyl`, dans `chisq.test` et non depuis le tableau de proportions ou de pourcentages formatés, créé par `adorn_percentages` ou `adorn_pct_formatting`. 

Le pipe à partir de la table de proportions *ne donne pas d'erreur* mais les résultats qu'il renvoie *sont absurdes*.

```{r chi1_fail,exercise=TRUE}
BeanSurvey %>%
  tabyl(VILLAGE,SELLBEANS) %>%
     adorn_percentages() %>%
        chisq.test()
```
Ne faites pas ça !


### Hypothèses

Il existe deux hypothèses clés pour qu'un test du chi-deux soit valide.

La première est similaire à celle du test t et du test de Wilcox. Nous avons besoin d'observations indépendantes. Si nous ne satisfaisons pas à cette hypothèse, nous devrons en apprendre davantage sur la modélisation statistique, plutôt que d'utiliser un test du chi-deux.


Il existe une autre hypothèse que nous devons respecter, liée à la taille de l'échantillon dans chaque catégorie.
Essayons de répondre à une question différente - si `HHTYPE` est lié à la vente de haricots. Voyez si vous pouvez faire correspondre les résultats ci-dessous :


```{r chi_q1_show,echo=FALSE}
BeanSurvey %>%
  tabyl(HHTYPE,SELLBEANS) 

BeanSurvey %>%
  tabyl(HHTYPE,SELLBEANS) %>%
     adorn_percentages()

BeanSurvey %>%
  tabyl(HHTYPE,SELLBEANS) %>%
    chisq.test()
```

```{r chi_q1,exercise=TRUE}

```

```{r chi_q1-solution}
BeanSurvey %>%
  tabyl(HHTYPE,SELLBEANS) 

BeanSurvey %>%
  tabyl(HHTYPE,SELLBEANS) %>%
     adorn_percentages()

BeanSurvey %>%
  tabyl(HHTYPE,SELLBEANS) %>%
    chisq.test()
```
Nous devons avoir un nombre suffisant d'observations dans toutes les combinaisons possibles des catégories de nos deux variables - dans cet exemple, nous voyons un message d'avertissement indiquant que "l'approximation du chi carré peut être incorrecte". La règle générale est d'avoir des fréquences attendues d'au moins cinq observations dans toutes les combinaisons - nous pouvons clairement voir que de nombreux types de ménages ont moins d'observations que cela dans l'ensemble, avant même de considérer s'ils ont vendu des haricots ou non. 

Dans ce cas, nous avons trois options pour traiter ce problème :  
1. Utiliser une variable différente - comme le sexe du chef de ménage. Dans ce cas, nous l'avons déjà dans nos données, mais si nous ne l'avions pas, nous pourrions la créer en utilisant `mutate` et ensuite la fonction `recode` qui est très utile à connaître.

/*Dans la fonction recode, nous fournissons d'abord la variable que nous recodons, puis nous spécifions comment nous voulons la recoder en suivant le modèle `"existing value" = "new value"`. Ainsi, toutes les catégories à tête féminine sont recodées dans la même nouvelle catégorie. En examinant les données, j'ai découvert que le ménage "autre" était dirigé par un homme. Mais si je recodais les données sans le savoir, il serait probablement plus judicieux de choisir de supprimer cette valeur en utilisant un `filtre`.*/

```{r chi_q2,exercise=TRUE}
BeanSurvey %>%
  mutate(HHTYPE2 = recode(HHTYPE,
                          "Femme chef de famille mari absent"="Femme chef de famille",
                           "Femme chef de famille, sans mari"="Femme chef de famille",
                          "Homme chef de famille, plus d'une épouse"="Homme chef de famille",
"Homme chef de famille avec une femme"="Homme chef de famille",
"Homme célibataire"="Homme chef de famille")) %>%
  filter(HHTYPE2!="Other") %>%
  tabyl(HHTYPE2,SELLBEANS)


```

Lorsque vous utilisez `janitor` et les fonctions `tabyl`, il est souvent judicieux de sauvegarder le `tabyl` initial en tant qu'objet. De cette façon, nous pouvons ensuite passer aux étapes suivantes, à savoir l'examen des pourcentages et la réalisation de tests d'hypothèse, sans avoir à répéter à chaque fois les étapes de manipulation des données.


```{r chi_q99,exercise=TRUE}
tabyl1<-BeanSurvey %>%
  mutate(HHTYPE2 = dplyr::recode(HHTYPE,
                          "Femme chef de famille mari absent" = "Femme chef de famille",
                          "Femme chef de famille, sans mari"="Femme chef de famille",
                          "Homme chef de famille, plus d'une épouse"="Homme chef de famille",
"Homme chef de famille avec une femme"="Homme chef de famille",
"Homme célibataire"="Homme chef de famille",
"Autre"="Homme chef de famille")) %>%
  tabyl(HHTYPE2,SELLBEANS)

tabyl1

tabyl1 %>%
  adorn_percentages()

tabyl1 %>%
    chisq.test()
```

2. N'incluez que les deux `HHTYPES` communs qui sont "Femme chef de famille, pas de mari", et "Homme chef de famille, une femme". Nous pourrions restreindre ceci en utilisant `filter`.

```{r chi_q3,exercise=TRUE}
tabyl2 <- BeanSurvey %>%
  filter(HHTYPE%in%c("Femme chef de famille, pas de mari", "Homme chef de famille, une femme")) %>%
  tabyl(HHTYPE,SELLBEANS)

tabyl2

tabyl2 %>%
  adorn_percentages()

tabyl2 %>%
    chisq.test()
```
Dans ce cas, nous obtenons toujours le même avertissement - parce que les fréquences dans la catégorie "femme chef, sans mari" sont encore un peu faibles.


3. Utiliser l'alternative non-paramétrique, le test exact de Fisher

Heureusement, tout comme avec la fonction `wilcox.test()`, nous pouvons utiliser un test non-paramétrique lorsque nous traitons deux variables catégorielles en changeant simplement le nom de la fonction de `chisq.test()` à `fisher.test()`.

```{r chi_q4,exercise=TRUE}
BeanSurvey %>%
  tabyl(HHTYPE,SELLBEANS) %>%
    fisher.test()
```
Quelle que soit la méthode utilisée ici, nous sommes arrivés à la même conclusion - aucune preuve de la relation entre le type de ménage et la vente de haricots. Mais remarquez que les hypothèses pour les options 1 et 2 sont différentes. Dans l'option 1, nous comparons les différences uniquement dans le sexe du chef de famille, sans tenir compte des autres compositions de ménage qui existent dans la variable `HHTYPE`. Et dans l'option 2, nous ne comparons que les deux types de ménages spécifiques.

Contrairement au `t-test()`, nous ne changeons pas l'hypothèse que nous testons en utilisant le test de Fisher à la place. Cependant, ce test est beaucoup plus coûteux en termes de calcul. Même avec un ensemble de données raisonnablement petit (200 observations environ), vous pouvez constater que l'ordinateur met un certain temps à renvoyer le résultat. C'est pourquoi le test du chi-deux est souvent préféré, car il est toujours très rapide à calculer pour l'ordinateur !



## Plus de tests ?

Ce sont les seuls tests d'hypothèse dont nous parlerons explicitement dans ce cours, mais nous espérons que vous verrez que la syntaxe pour produire ces tests n'est pas particulièrement compliquée. Ceci est vrai pour tous les tests d'hypothèse statistiques couramment utilisés. 

Si vous connaissez le test statistique simple que vous souhaitez effectuer, que vos données sont dans le format approprié pour ce test et que les hypothèses de ce test peuvent être satisfaites, il est généralement assez simple de trouver puis d'écrire le code R pour effectuer le test. Il existe un grand nombre de tests statistiques dans base-R !

```{r,echo=FALSE}
apropos("\\.test")
```

Et ce ne sont que les tests qui sont dans base-R - il y en aura beaucoup plus dans diverses bibliothèques supplémentaires !

Mais 'obtenir des données dans le format approprié', 'vérifier les hypothèses du test' et 'savoir si le test d'hypothèse a un sens pour votre question' ne sont pas si simples ! Il est incroyablement facile de faire une analyse de données catastrophique dans R, en passant directement à la valeur p finale et en produisant des valeurs p sans signification. C'est un peu comme conduire une voiture : n'importe qui peut appuyer sur l'accélérateur et faire avancer la voiture, mais si vous ne savez pas comment changer les vitesses ou si vous ignorez complètement tous les panneaux de signalisation, vous allez probablement vous écraser.

Ceci n'est, bien sûr, pas seulement vrai pour R mais pour tout logiciel d'analyse. Cependant, avec R, vous avez encore moins d'excuses pour agir de la sorte, puisque tous les outils nécessaires pour éviter cela sont fournis et disponibles gratuitement. C'est pourquoi nous avons mis l'accent dans ce cours sur la manipulation des données (`dplyr`), les graphiques exploratoires (`ggplot2`) et l'utilisation d'un workflow cohérent et reproductible (RStudio). 

Lorsque vous effectuez des recherches dans le monde réel, il est extrêmement improbable qu'un simple test d'hypothèse soit suffisant pour votre analyse. Mais ce sont souvent ces tests que l'on vous enseigne dans vos modules de statistique, car ils constituent la première étape vers des modèles statistiques plus largement applicables. Il est probable que vous aurez besoin de faire de la modélisation statistique pour mieux expliquer les modèles et les tendances de vos données. Nous en apprendrons davantage à ce sujet dans le prochain module !

## Exercices

Dans ce module, les exercices sont un peu différents. C'est à vous d'utiliser RStudio pour réaliser les exercices sur votre propre ordinateur.

Vous pouvez télécharger les fichiers dont vous avez besoin [en cliquant sur ce lien ici](https://github.com/stats4sd/R4CCRP_06_StatsTest/blob/main/Module%206%20Exercises.zip?raw=true)


Assurez-vous de les décompresser dans un nouveau dossier, puis de démarrer un nouveau fichier de projet basé sur ce dossier, comme nous l'avons appris dans le module précédent.

Il se peut que vous deviez installer l'un des paquets utilisés avant de continuer - assurez-vous que vous les avez installés et chargés, en exécutant le premier morceau de code, avant d'essayer de commencer à résoudre les questions !

## Références  

Vidéo sur l'interprétation des valeurs p (Dr Nic's Maths and Stats):  
https://www.youtube.com/watch?v=eyknGvncKLw  

Vidéo sur le choix d'un test approprié (Dr Nic)
https://www.youtube.com/watch?v=rulIUAN0U3w

Tutoriel sur les tests t et leurs équivalents non paramétriques (Guide de programmation R pour UC Business Analytics):  
https://larmarange.github.io/analyse-R/comparaisons-moyennes-et-proportions.html  

Tutoriel couvrant plus en détail tous les tests abordés dans cette session. (Note - La partie I (tests du chi carré) est beaucoup plus compliquée dans ce tutoriel que la méthode que nous avons montrée ! Nous vous suggérons de ne travailler que sur les parties II et III).
https://sbc.shef.ac.uk/workshops/2019-09-18-stats-r/practical.nb.html


